# 第一章：Roofline 模型详解
## 🎯 分页演讲文档与脚本

> **演讲风格指南**：白话、平易近人、深入浅出、引经据典、适度幽默
> **目标受众**：对 LLM 有基本了解，但不熟悉底层性能优化的学生和开发者
> **预计时长**：45-60 分钟

---

# 📄 第 1 页：为什么你的模型跑得慢？

## 📊 幻灯片内容

### 标题：你的模型，卡在哪了？

**核心问题：**
- 为什么同一个模型，跑 50ms 而不是 50s 或者 5ms？
- 时间都花在哪儿了？

**三个可能的瓶颈：**
1. 🧮 计算太慢（CPU/GPU 算不过来）
2. 📦 数据搬运太慢（内存带宽不够）
3. 🔗 多卡通信太慢（卡和卡之间传数据）

**今日目标：** 学会判断你的模型卡在哪个瓶颈上

---

## 🎤 演讲脚本

同学们好！今天我们来聊一个既实用又有趣的话题——**为什么你的模型跑得慢？**

你有没有遇到过这种情况：写了一个模型，跑起来慢得像蜗牛，但又不知道问题出在哪儿？是代码写得太烂？还是硬件不够强？还是哪里有 bug？

**先讲个故事。**

1995 年，有两个科学家——David Patterson 和 Samuel Williams（后来还有 Roofline 论文的 Andrew Waterman）——他们面对一个问题：当时的超级计算机越来越快，但很多程序的速度提升却远不如预期。为什么？

他们发现，问题不在于 CPU 有多快，而在于**数据能不能及时送到 CPU 手里**。

这就像你雇了一个打字速度 1000 字/分钟的超级打字员，但你只能每分钟递给他 10 个字的稿子——他再快也没用，大部分时间都在干等。

这个故事告诉我们：**性能优化，首先得搞清楚瓶颈在哪。**

今天我们要学的 **Roofline 模型**，就是帮你快速判断"瓶颈在哪"的利器。学完之后，你看任何一个算法，都能大致估算它能跑多快、卡在哪里。

那么，时间到底花在哪了呢？主要是三件事：

1. **计算**——做加法、乘法这些运算
2. **芯片内搬运数据**——从内存把数据搬到计算核心
3. **芯片间搬运数据**——多张卡之间互相传数据

接下来，我们逐个拆解。

---

# 📄 第 2 页：三个时间杀手

## 📊 幻灯片内容

### 标题：时间杀手 1️⃣2️⃣3️⃣

**杀手 1：计算时间**
$$T_{\text{计算}} = \frac{\text{FLOPs 总量}}{\text{芯片算力 (FLOPs/s)}}$$

| 芯片 | bf16 算力 |
|------|-----------|
| NVIDIA H100 | ~9.89×10¹⁴ FLOPs/s |
| Google TPU v6e | ~9.1×10¹⁴ FLOPs/s |

**杀手 2：芯片内通信**
$$T_{\text{内存}} = \frac{\text{数据量 (Bytes)}}{\text{HBM 带宽 (Bytes/s)}}$$

| 芯片 | HBM 带宽 |
|------|----------|
| H100 | 3.35 TB/s |
| TPU v6e | 1.6 TB/s |

**杀手 3：芯片间通信**
- NVLink / ICI / PCIe
- 带宽比 HBM 低 1-2 个数量级

---

## 🎤 演讲脚本

好，让我们来认识这三个"时间杀手"。

### 杀手 1：计算时间

深度学习的本质是什么？说白了就是**一大堆矩阵乘法**。每个矩阵乘法又是由无数个浮点加法和乘法组成的。

我们把这些运算叫做 **FLOPs**——Floating-point Operations，浮点运算。

> 💡 **小知识**：FLOPs 指的是"运算次数"，而 FLOPs/s（或 FLOPS）指的是"每秒运算次数"。很多文章混用，我们这里用 FLOPs/s 表示后者。

计算时间怎么算？**超级简单的小学除法：**

$$T_{\text{计算}} = \frac{\text{要做多少次运算}}{\text{每秒能做多少次}}$$

举个例子：NVIDIA H100 的 bf16 算力大约是 **9.89×10¹⁴ FLOPs/s**——也就是每秒差不多能做 1000 万亿次运算！

如果你的模型需要做 1 万亿次运算（10¹²），那计算时间大约是：

$$\frac{10^{12}}{9.89 \times 10^{14}} \approx 1\text{ms}$$

1毫秒！听起来很快对吧？但别急，还有两个杀手等着呢。

### 杀手 2：芯片内通信

数据存在哪里？存在"显存"（HBM）里。但计算核心（比如 TPU 的 MXU 或 GPU 的 Tensor Core）需要数据才能干活。

问题来了：**数据得从显存搬到计算核心**，这个搬运也需要时间！

这就像工厂里的流水线：机器（计算核心）再快，如果原材料（数据）送不过来，机器就得停工等待。

搬运速度取决于 **内存带宽**：

| 芯片 | HBM 带宽 |
|------|----------|
| H100 | 3.35 TB/s（每秒 3.35 万亿字节）|
| TPU v6e | 1.6 TB/s |

### 杀手 3：芯片间通信

当你的模型大到一张卡放不下，就需要**多张卡一起干活**。

但多张卡之间也得互相传数据——你算完的东西，可能需要传给别的卡用。这个"传数据"也是有时间成本的。

常见的连接方式：
- **NVLink**（NVIDIA 的卡间连接，很快）
- **ICI**（TPU 的卡间连接，也很快）
- **PCIe**（通用接口，相对较慢）

这些带宽比 HBM 要低 1-2 个数量级——这意味着**多卡通信往往是更大的瓶颈**。

---

**好消息来了！**

计算和通信通常可以**重叠进行**——一边算，一边传。所以：

- **最好情况（完美重叠）**：总时间 = max(计算时间, 通信时间)
- **最坏情况（完全不重叠）**：总时间 = 计算时间 + 通信时间

实际情况在这两者之间。我们通常按"最好情况"来优化，因为最好和最坏最多差 2 倍——在数量级估算时，2 倍是可以接受的误差。

---

# 📄 第 3 页：算术强度登场

## 📊 幻灯片内容

### 标题：一个数字看穿本质——算术强度

**计算受限 vs 通信受限**
- 计算时间 > 通信时间 → ✅ 计算受限（好事！）
- 通信时间 > 计算时间 → ❌ 通信受限（浪费算力！）

**算术强度（Arithmetic Intensity）**
$$\text{算术强度} = \frac{\text{FLOPs}}{\text{Bytes}} \quad (\text{单位: FLOPs/Byte})$$

> 直觉：每搬运 1 字节数据，能做多少次运算？

**临界算术强度**
$$\text{临界强度} = \frac{\text{芯片算力}}{\text{带宽}} = \frac{\text{FLOPs/s}}{\text{Bytes/s}}$$

**判断法则：**
- 你的算法强度 > 临界强度 → 计算受限 ✅
- 你的算法强度 < 临界强度 → 通信受限 ❌

**TPU v5e MXU 临界强度 ≈ 240 FLOPs/Byte**

---

## 🎤 演讲脚本

好，现在你知道了有三个时间杀手。但问题来了：**怎么快速判断谁是老大？**

每次都算一遍时间太麻烦了。有没有更简单的方法？

有！就是**算术强度**。

### 什么是算术强度？

很简单：

$$\text{算术强度} = \frac{\text{做了多少次运算}}{\text{搬了多少字节数据}}$$

单位是 **FLOPs/Byte**——每搬运 1 字节数据，做多少次运算。

**直觉理解：**

想象你是一个快递员，要送货（数据）给工人（计算核心）。算术强度就是：每送一趟货，工人能干多少活。

- 如果工人干活很快，但你送货很慢 → **工人老是等货**（通信受限）
- 如果你送货很快，但工人干活慢 → **货堆着没人处理**（计算受限）

理想情况是什么？**送货速度刚好跟得上工人干活的速度**。

### 临界算术强度

每个硬件都有一个"临界点"——**临界算术强度**：

$$\text{临界强度} = \frac{\text{算力}}{\text{带宽}}$$

拿 TPU v5e 的 MXU（矩阵乘法单元）来说：

$$\text{临界强度} = \frac{1.97 \times 10^{14} \text{ FLOPs/s}}{8.2 \times 10^{11} \text{ Bytes/s}} \approx 240 \text{ FLOPs/Byte}$$

**这个数字的含义是：**

如果你的算法每搬运 1 字节能做 240 次以上运算，恭喜你，**计算是瓶颈**——这意味着你充分利用了芯片的算力！

如果做不到 240 次，那**通信是瓶颈**——芯片算力被浪费了，有一部分时间在干等数据。

> 🎯 **金句**：算术强度就像"性价比"——每搬运 1 字节数据能做多少活。性价比越高，硬件利用率越高。

---

# 📄 第 4 页：点积的悲剧

## 📊 幻灯片内容

### 标题：点积——一个悲伤的故事

**场景**：计算两个 bf16 向量的点积 $\mathbf{x} \cdot \mathbf{y}$（长度为 N）

**搬运多少数据？**
- 加载 x：2N 字节
- 加载 y：2N 字节
- 写回结果：2 字节
- **总计：4N + 2 字节**

**做多少运算？**
- N 次乘法
- N-1 次加法
- **总计：2N - 1 次**

**算术强度：**
$$\text{强度} = \frac{2N - 1}{4N + 2} \approx \frac{1}{2}$$

**对比临界强度 240…… 💀**

> 点积是典型的**通信受限**操作！

---

## 🎤 演讲脚本

让我们来看一个真实的例子——**点积**。

点积大家都熟悉吧？两个向量，对应位置相乘，然后加起来：

$$\mathbf{x} \cdot \mathbf{y} = x_1 y_1 + x_2 y_2 + \cdots + x_N y_N$$

假设我们用的是 bf16（每个数占 2 字节），向量长度是 N。

**搬运多少数据？**
- 加载向量 x：N 个数 × 2 字节 = 2N 字节
- 加载向量 y：同样 2N 字节
- 写回结果（一个标量）：2 字节
- **总计：4N + 2 字节**

**做多少运算？**
- N 次乘法（x₁×y₁, x₂×y₂, ...）
- N-1 次加法（把它们加起来）
- **总计：2N - 1 次**

**算术强度呢？**

$$\text{强度} = \frac{2N - 1}{4N + 2}$$

当 N 很大时，这个值趋近于……**0.5**！

而临界强度是多少？**240**！

0.5 vs 240，差了将近 500 倍！

**这意味着什么？**

点积操作，**几乎所有时间都在等数据**。芯片的算力根本用不上！

这就像你雇了一个超级数学家（每秒能算 240 道题），但你只能每秒给他送 1 道题——他 99.5% 的时间都在摸鱼。

**这就是点积的悲剧**——它是典型的**通信受限**操作。

> 💡 **小知识**：这也是为什么 GPU/TPU 上很多"逐元素运算"（比如激活函数、归一化）效率不高的原因——它们的算术强度都很低。

那有没有高算术强度的操作呢？有！就是我们接下来要讲的**矩阵乘法**。

---

# 📄 第 5 页：Roofline 图

## 📊 幻灯片内容

### 标题：一张图看懂性能瓶颈

**Roofline 图**

```
   FLOPs/s
      ↑
  峰值 ├────────────────────────── 天花板（算力极限）
      │                    ╱
      │                  ╱
      │                ╱  斜坡（带宽限制）
      │              ╱
      │            ╱
      │          ╱
      └────────────────────────→ 算术强度
              临界点
```

**图的解读：**
- **斜坡区域**（左边）：通信受限，性能随强度线性增长
- **平台区域**（右边）：计算受限，性能达到峰值
- **拐点**：临界算术强度

**三种操作的位置：**
- 点积：强度 ≈ 0.5，深陷斜坡区 😢
- 小矩阵乘法：强度适中，可能在拐点附近
- 大矩阵乘法：强度高，顶到天花板 ✅

---

## 🎤 演讲脚本

刚才讲了这么多数字，有没有更直观的方式来理解？

有！就是 **Roofline 图**。

Roofline 图长什么样呢？

想象一个房子的侧面图：
- **天花板**：一条水平线，代表芯片的峰值算力
- **斜坡**：从原点向上的一条斜线，斜率是带宽

两条线交汇的地方，就是**临界点**。

**怎么看这张图？**

你的算法是一个点，横坐标是算术强度，纵坐标是能达到的性能。

- 如果你在**斜坡上**（临界点左边）：你被"屋顶的斜坡"压住了——**通信受限**
- 如果你在**天花板下**（临界点右边）：你顶到了"天花板"——**计算受限**

**斜坡区域**意味着：你的性能和算术强度成正比。强度翻倍，性能翻倍。但无论怎么提高，都被斜坡压着，达不到峰值。

**天花板区域**意味着：你已经充分利用了算力，再提高强度也没用了——因为已经顶到天花板了。

> 🎨 **有趣的比喻**：这就像跑步比赛。
> - 斜坡区 = 你还没热身好，速度和热身程度成正比
> - 天花板区 = 你已经全力冲刺了，再怎么努力也就这个速度了

**Roofline 图的名字由来**

现在你知道为什么叫 "Roofline"（屋顶线）了吧？因为这张图看起来就像一个房子的屋顶——有斜坡，有平台。

你的目标是什么？**让算法爬到屋顶的平台上**——那里才是性能最高的地方。

---

# 📄 第 6 页：矩阵乘法的 Roofline

## 📊 幻灯片内容

### 标题：矩阵乘法——深度学习的心脏

**场景**：$X_{[B,D]} \times Y_{[D,F]} \rightarrow Z_{[B,F]}$（bf16）

**搬运多少？**
- 加载 X：2BD 字节
- 加载 Y：2DF 字节
- 写回 Z：2BF 字节
- **总计：2(BD + DF + BF) 字节**

**做多少运算？**
- **2BDF FLOPs**

**算术强度：**
$$\text{强度} = \frac{2BDF}{2(BD + DF + BF)} = \frac{BDF}{BD + DF + BF}$$

**简化（当 D,F >> B 时）：**
$$\text{强度} \approx \frac{BDF}{DF} = B$$

**🎯 黄金法则：bf16 矩阵乘法要跑满算力，batch size > 240！**

---

## 🎤 演讲脚本

好，终于到了深度学习的核心操作——**矩阵乘法**！

矩阵乘法是 Transformer 的心脏。注意力机制、FFN 层，背后都是矩阵乘法。如果矩阵乘法慢，整个模型都快不了。

让我们算算它的算术强度。

**场景设定**：
- X 的形状是 [B, D]（B 是 batch size，D 是特征维度）
- Y 的形状是 [D, F]
- 输出 Z 的形状是 [B, F]
- 全部用 bf16（每个数 2 字节）

**搬运多少数据？**
- 加载 X：B × D × 2 = 2BD 字节
- 加载 Y：D × F × 2 = 2DF 字节
- 写回 Z：B × F × 2 = 2BF 字节
- **总计：2(BD + DF + BF) 字节**

**做多少运算？**

矩阵乘法的运算量怎么算？输出的每个元素需要 D 次乘法和 D-1 次加法，输出一共 B×F 个元素，所以总共约 **2BDF FLOPs**。

**算术强度：**

$$\text{强度} = \frac{2BDF}{2(BD + DF + BF)} = \frac{BDF}{BD + DF + BF}$$

这个公式看起来有点复杂。我们做个简化。

在 Transformer 里，D 和 F 通常很大（比如 4096、8192），而 B 相对较小。这时候分母里 DF 这一项最大，所以：

$$\text{强度} \approx \frac{BDF}{DF} = B$$

**惊人的结论：算术强度约等于 batch size！**

还记得临界强度是多少吗？**240**。

所以：

> 🎯 **黄金法则**：在 TPU 上跑 bf16 矩阵乘法，如果想充分利用算力，每张卡的 batch size 至少要 **240 个 token**！

低于这个数字，就会变成通信受限——有一部分算力被浪费了。

**这解释了很多现象**：

1. 为什么训练时要用大 batch？——保证每卡 batch size 够大
2. 为什么推理时小 batch 效率低？——强度不够
3. 为什么模型越大，需要的 batch 可以相对越小？——因为 D 和 F 变大了

> 💡 **练习**：如果用 int8 代替 bf16（每个数只占 1 字节），临界 batch size 会变成多少？提示：搬运的数据量减半了！

---

# 📄 第 7 页：多卡并行的 Roofline

## 📊 幻灯片内容

### 标题：从单机到分布式——游戏规则变了！

**场景**：两张 TPU 联合做矩阵乘法

**分布式策略：**
- X 和 Y 沿 D 维度各存一半
- TPU 0 算：X[:, :D/2] @ Y[:D/2, :]
- TPU 1 算：X[:, D/2:] @ Y[D/2:, :]
- 交换结果，求和得到 Z

**时间对比**

| | 单卡 | 双卡 |
|--|------|------|
| 计算时间 | $\frac{2BDF}{\text{算力}}$ | $\frac{BDF}{\text{算力}}$ ⬇️减半 |
| 通信时间 | $\frac{2(BD+DF+BF)}{\text{HBM带宽}}$ | $\frac{2BF}{\text{卡间带宽}}$ 🔄不同了 |

**临界条件变化：**
- 单卡：临界 batch size ≈ 240
- 双卡：临界模型宽度 D > 8755

**🎯 关键洞察：多卡时，瓶颈从 batch size 变成了模型宽度！**

---

## 🎤 演讲脚本

到目前为止，我们讲的都是**单张卡**的情况。但现在训练大模型，动不动就是几百上千张卡。

当引入多卡，游戏规则就变了！

**来看一个简单的例子**：

假设我们有两张 TPU，要一起做一个矩阵乘法。怎么分工？

一种常见的做法：
1. 把 X 和 Y 沿着 D 维度各切一半
2. TPU 0 负责前半部分：X[:, :D/2] @ Y[:D/2, :]
3. TPU 1 负责后半部分：X[:, D/2:] @ Y[D/2:, :]
4. 两边各自算完，得到"部分和"
5. 把部分和发给对方，加起来，就是最终结果

**计算时间怎么变？**

每张卡只算一半，所以计算时间**减半**！这是多卡的好处。

**通信时间怎么变？**

这是关键！现在的通信不是"从显存到计算核心"，而是"从一张卡到另一张卡"。

需要传的是什么？**部分和**——形状是 [B, F]，大小 2BF 字节。

通过什么传？**卡间连接**（比如 TPU 的 ICI）。ICI 带宽大约 4.5×10¹⁰ Bytes/s——比 HBM 带宽低了一个数量级！

**新的临界条件**：

什么时候计算受限？

$$T_{\text{计算}} > T_{\text{通信}}$$

$$\frac{BDF / 2}{\text{算力}} > \frac{2BF}{\text{ICI带宽}}$$

简化后：

$$D > 2 \times \frac{\text{算力}}{\text{ICI带宽}} \approx 8755$$

**发现了什么？**

- 单卡时，临界条件看的是 **B（batch size）**
- 多卡时，临界条件看的是 **D（模型宽度）**

**这意味着**：

1. 模型越宽（D 越大），多卡扩展效果越好
2. 窄模型即使加再多卡，也可能被卡间通信拖累
3. 这就是为什么大模型训练要用"够宽"的架构！

> 💡 **思考题**：如果有 4 张卡呢？8 张卡呢？通信量会怎么变化？临界条件会怎么变？

---

# 📄 第 8 页：总结与思考

## 📊 幻灯片内容

### 标题：Roofline 模型——你的性能诊断工具

**三个核心公式**

1. **时间估算**
$$T = \max(T_{\text{计算}}, T_{\text{通信}}) \quad \text{到} \quad T_{\text{计算}} + T_{\text{通信}}$$

2. **算术强度**
$$\text{强度} = \frac{\text{FLOPs}}{\text{Bytes}}$$

3. **临界判断**
$$\text{强度} \gtrless \frac{\text{算力}}{\text{带宽}} \Rightarrow \text{计算/通信 受限}$$

**黄金法则**

| 场景 | 要满足的条件 |
|------|-------------|
| 单卡 bf16 matmul | Batch size > 240 |
| 多卡并行 | 模型宽度 D > 临界值 |
| int8 量化 | 临界 batch size 更低 |

**下一步**
- 第 2 章：TPU 内部结构详解
- 第 3 章：分片与多卡矩阵乘法

---

## 🎤 演讲脚本

好，我们来总结一下今天学到的内容。

**Roofline 模型告诉我们什么？**

1. **性能有三个天花板**：计算、芯片内通信、芯片间通信。你的程序会被其中一个卡住。

2. **算术强度是关键指标**：每搬运 1 字节能做多少运算？这个数字决定了你是计算受限还是通信受限。

3. **计算受限是好事**：意味着你充分利用了硬件算力。通信受限是坏事——有算力在浪费。

4. **矩阵乘法的强度约等于 batch size**：所以大 batch 训练不是迷信，是有道理的。

5. **多卡时规则变了**：从"batch size 要够大"变成"模型要够宽"。

**几个实用的数字**

| 情况 | 临界值 |
|------|--------|
| TPU v5e 单卡 bf16 matmul | B > 240 |
| H100 单卡 bf16 matmul | B > 300 |
| 多卡扩展（TPU ICI） | D > 8755 |

记住这些数字，以后估算性能时会很有用。

**最后，留几个思考题**

1. 如果用 fp32 代替 bf16，算术强度会怎么变？

2. 注意力机制的算术强度是多少？它是计算受限还是通信受限？

3. 如果你的模型只有 D=1024，在多卡上扩展效果会好吗？

**下一章预告**

Roofline 模型给了我们分析性能的框架，但要真正理解"为什么是这样"，我们需要深入了解硬件的内部结构。

下一章，我们会打开 TPU 的"黑盒子"，看看里面到底是怎么工作的。

同学们，我们下节课见！

---

# 📚 附录：课后资源

## 推荐阅读

1. **Roofline 论文原文**：Williams, S., Waterman, A., & Patterson, D. (2009). "Roofline: An Insightful Visual Performance Model for Multicore Architectures"

2. **NVIDIA H100 规格表**：https://www.nvidia.com/en-us/data-center/h100/

3. **Google TPU 文档**：https://cloud.google.com/tpu/docs

## 练习题答案提示

**题 1（int8 矩阵乘法）**：搬运量减半，运算量不变，所以强度翻倍。临界 batch size 约 120。

**题 2（权重量化）**：权重 int8 + 激活 bf16，临界 batch size 约 120。

**题 3（Roofline 图）**：大模型（D=4096）更早达到峰值。

**题 4（batch 维度权重）**：强度变成常数 2，几乎总是通信受限。

**题 5（H100 临界值）**：约 300。

---

*文档版本：v1.0*
*最后更新：2024-12*
*适用章节：第一章 Roofline 模型详解*